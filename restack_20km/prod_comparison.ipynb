{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6581d610-cb64-4ad6-aa3e-5a61cb816a6b",
   "metadata": {},
   "source": [
    "# Validate new restacked data with production data\n",
    "\n",
    "This notebook is for ensuring that the newest restacked WRF data, created as an upgrade replacement for the existing dataset, matches the existing production dataset (where expected - some productiond data do have errors and should not match new data). \n",
    "\n",
    "This notebook is NOT expected to maintain the same functionality, as the existing production dataset will be overwritten after ensuring the new data match it where expected. Rather, it will serve as a historical record for the Great Restacking of 2022.\n",
    "\n",
    "## Strategy\n",
    "\n",
    "This notebook will check consistency by comparing some number of random slices in time between new outputs and existing production data for every combination of model, scenario, year, and variable.\n",
    "\n",
    "Given space constraints, it will not be feasible to run a comparison with all potential model/scenario combinations at once it seems to make the most sense to update this notebook after the completion of restacking each of the five WRF groups. So, once a WRF group has been restacked, run the validation in the correct section below before overwriting the production data. \n",
    "\n",
    "**Make sure to commit changes for the correct WRF group.**\n",
    "\n",
    "## Validation\n",
    "\n",
    "### Setup\n",
    "\n",
    "Execute the cells in this section to set up the environment before attempting to validate any of the WRF groups.\n",
    "\n",
    "Set up directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21579973-5686-401b-9435-fb5345a17474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import luts\n",
    "\n",
    "\n",
    "# these paths should be constant for any SNAPer running this pipeline\n",
    "# assumes all folders are created in restack_20km.ipynb\n",
    "base_dir = Path(\"/import/SNAP/wrf_data/project_data/wrf_data\")\n",
    "# final output directory for data\n",
    "restack_prod_dir = base_dir.joinpath(\"hourly_fix\")\n",
    "anc_dir = base_dir.joinpath(\"ancillary\")\n",
    "\n",
    "scratch_dir = Path(\"/center1/DYNDOWN/kmredilla/wrf_data\")\n",
    "# where initially restacked data are stored on scratch_space\n",
    "restack_scratch_dir = scratch_dir.joinpath(\"restacked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a51473-4651-441f-90a3-62e378fda0b6",
   "metadata": {},
   "source": [
    "Define a function that will compare randomly selected slices in time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e9acf-e665-46fb-be45-fad0a38ec3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def validate_slice(restack_fp, restack_dir):\n",
    "    \"\"\"Compares the values of restacked data with those in\n",
    "    an existing production data file\n",
    "    \n",
    "    Args:\n",
    "        restack_scratch_fp (pathlib.PosixPath): path to file containing\n",
    "            restacked data to check that is on scratch space\n",
    "        restack_prod_dir (pathlib.PosixPath): path to the directory containing\n",
    "            the full production dataset\n",
    "    \n",
    "    Returns:\n",
    "        dict with keys variable, timestamp, and result as keys\n",
    "    \"\"\"\n",
    "    varname = restack_fp.parent.name\n",
    "    with xr.open_dataset(restack_fp) as ds:\n",
    "        idx = np.random.randint(ds.time.values.shape[0])\n",
    "        check_time = ds.time.values[idx]\n",
    "        check_arr = ds[varname].sel(time=check_time).values\n",
    "        \n",
    "    fix_fp = base_dir.joinpath(f\"{varname}/{restack_fp.name}\")\n",
    "    with xr.open_dataset(fix_fp) as ds:\n",
    "        fix_arr = ds[varname].sel(time=check_time).values\n",
    "        \n",
    "    check = np.all(fix_arr == check_arr)\n",
    "\n",
    "    wrf_time_str = str(check_time.astype(\"datetime64[h]\")).replace(\"T\", \"_\")\n",
    "    result = {\n",
    "        \"varname\": varname,\n",
    "        \"timestamp\": wrf_time_str,\n",
    "        \"match\": check\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65aad84d-6823-44f1-81f5-8c78f71f01c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def validate(restack_fp, restack_dir):\n",
    "    \"\"\"Compares the values of restacked data with those in\n",
    "    an existing production data file\n",
    "    \n",
    "    Args:\n",
    "        restack_scratch_fp (pathlib.PosixPath): path to file containing\n",
    "            restacked data to check that is on scratch space\n",
    "        restack_prod_dir (pathlib.PosixPath): path to the directory containing\n",
    "            the full production dataset\n",
    "    \n",
    "    Returns:\n",
    "        dict with keys variable, timestamp, and result as keys\n",
    "    \"\"\"\n",
    "    varname = restack_fp.parent.name\n",
    "    fix_fp = base_dir.joinpath(f\"{varname}/{restack_fp.name}\")\n",
    "\n",
    "    with xr.open_dataset(restack_fp) as ds:\n",
    "        # idx = np.random.randint(ds.time.values.shape[0])\n",
    "        # check_time = ds.time.values[idx]\n",
    "        check_arr = ds[varname].values\n",
    "        \n",
    "        with xr.open_dataset(fix_fp) as ds:\n",
    "            prod_arr = ds[varname].values\n",
    "            \n",
    "            check = np.all(prod_arr == check_arr)\n",
    "\n",
    "    result = {\n",
    "        \"varname\": varname,\n",
    "        \"match\": check\n",
    "    }\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f0a86-ec0c-4a26-9206-e32113eda900",
   "metadata": {},
   "source": [
    "Define a function to iterate over all files of the WRF group and run the comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317fb92e-955f-46c0-96a8-c75f379798d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tic = time.perf_counter()\n",
    "\n",
    "results = []\n",
    "for varname in luts.varnames:\n",
    "    group = luts.group_fn_lu[f\"{model}_{scenario}\"]\n",
    "    years = luts.groups[group][\"years\"]\n",
    "    for year in years:\n",
    "        fn = f\"{varname}_hourly_wrf_{model}_{scenario}_{year}.nc\"\n",
    "        restack_scratch_fp = restack_scratch_dir.joinpath(fn)\n",
    "        result_di = validate_slice(restack_scratch_fp, restack_prod_dir)\n",
    "        result_di.update({\"model\": model, \"scenario\": scenario})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f456e-fb7f-42fb-9338-bf587742b599",
   "metadata": {},
   "source": [
    "### ERA-Interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c41c393-815c-4ae3-a00e-1590326f8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrf_group = \"erain_hist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce780098-760b-4b0e-96b3-b0792019125f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91870b23-922d-43e0-863f-2704e9776279",
   "metadata": {},
   "source": [
    "### NCAR-CCSM Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bff2c7a-f593-46cb-adbd-897646581b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = \"ccsm_hist\"\n",
    "years = luts.groups[group][\"years\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5663813-f9df-454d-96e8-74763737c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    " = \n",
    "fn = f\"{varname}_hourly_wrf_{luts.groups[group][\"fn_s}_{year}.nc\"\n",
    "restack_scratch_fp = restack_scratch_dir.joinpath(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b22ea7-bf6c-4fec-9acf-f31146a917b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
