{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf68d2c-ba70-4aa5-8021-74a79d12fe9a",
   "metadata": {},
   "source": [
    "# Utilities for restacking pipeline\n",
    "\n",
    "This notebook is a collection of various utility functions that can be used to assist with running the pipeline. \n",
    "\n",
    "Run the cell below to set up the environment before moving on to other parts of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969b2ea8-e390-4168-b9ff-6caca76b45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "import luts\n",
    "import restack_20km as main\n",
    "\n",
    "years = luts.groups[group][\"years\"]\n",
    "wrf_dir = Path(luts.groups[group][\"directory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d5b38d-3855-486f-81e2-bfb244fe7bc4",
   "metadata": {},
   "source": [
    "### Inspect the filesystem\n",
    "\n",
    "This section just provides some info on the system we are working with here.\n",
    "\n",
    "The WRF outputs of interest from different runs of model / scenario may be in separate directories, but there is consistency in file structure across all groups - all `hourly` and `daily` directories have annual subgroups consisting of the WRF outputs to be restacked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f23e0f59-ba5c-454e-9bdc-ba8687977208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;27m1970\u001b[0m/\n",
      "\u001b[38;5;27m1971\u001b[0m/\n",
      "\u001b[38;5;27m1972\u001b[0m/\n",
      "\u001b[38;5;27m1973\u001b[0m/\n",
      "\u001b[38;5;27m1974\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /archive/DYNDOWN/DIONE/pbieniek/ccsm/hist/hourly | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db92a061-bbc8-4f5f-88c7-28adad2a1cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;27m2003\u001b[0m/\n",
      "\u001b[38;5;27m2004\u001b[0m/\n",
      "\u001b[38;5;27m2005\u001b[0m/\n",
      "nohup.out\n",
      "\u001b[38;5;34morgdata.sh\u001b[0m*\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "ls /archive/DYNDOWN/DIONE/pbieniek/ccsm/hist/hourly/ | tail -6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e83f7d52-768b-457b-a4d6-93b1a05d82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;34mdailylog.out\u001b[0m*\n",
      "\u001b[38;5;34mWRFDS_d01.1979-01-01_00.nc\u001b[0m*\n",
      "\u001b[38;5;34mWRFDS_d01.1979-01-01_01.nc\u001b[0m*\n",
      "\u001b[38;5;34mWRFDS_d01.1979-01-01_02.nc\u001b[0m*\n",
      "\u001b[38;5;34mWRFDS_d01.1979-01-01_03.nc\u001b[0m*\n",
      "ls: write error\n"
     ]
    }
   ],
   "source": [
    "ls /archive/DYNDOWN/DIONE/pbieniek/ccsm/hist/hourly/1979 | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2bc706-f998-42ed-8fb6-3551d14a55fe",
   "metadata": {},
   "source": [
    "This structure applies for all outputs, and exists for the following model / scenario / year combinations:\n",
    "\n",
    "* ERA-Interim\n",
    "    * \"historical\": 1979-2015\n",
    "* GFDL-CM3\n",
    "    * historical: 1970-2006\n",
    "    * RCP 8.5: 2006-2100\n",
    "* NCAR-CCSM4\n",
    "    * historical: 1970-2005\n",
    "    * RCP 8.5: 2005-2100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17dc8ac-0922-4899-b596-767c1cc260eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### System\n",
    "\n",
    "This pipeline is being developed on the Chinook cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3f78b9-5275-46c1-943b-d3f7c7107c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux chinook00.rcs.alaska.edu 2.6.32-754.35.1.el6.61015g0000.x86_64 #1 SMP Mon Dec 21 12:41:07 EST 2020 x86_64 x86_64 x86_64 GNU/Linux\n"
     ]
    }
   ],
   "source": [
    "!uname -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d8782-96c7-4af8-aa0c-755b0c99e2b6",
   "metadata": {},
   "source": [
    "This pipeline makes use of slurm and multiple cores / compute nodes for processing in reasonable time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e62f094d-c58b-4204-a46b-20a2c4ae576d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slurm 19.05.7\n"
     ]
    }
   ],
   "source": [
    "!sinfo -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbb038d-4534-43f6-92a0-5dc9c967b29a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ensure ancillary WRF geogrid file is present\n",
    "\n",
    "The restacking will rely on a WRF geogrid data file for determining correct spatial projection information, and for correctly rotating data for wind variables. Make sure that it is present in the `anc_dir` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae92711-2e13-4995-82c9-491d4674b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not geogrid_fp.exists():\n",
    "    # the original location of this file is not known, in case it is ever deleted\n",
    "    #  from this source location it might still be available on Poseidon at \n",
    "    #  /workspace/Shared/Tech_Projects/wrf_data/project_data/ancillary_wrf_constants/geo_em.d01.nc\n",
    "    shutil.copy(\"/import/SNAP/wrf_data/project_data/ancillary_wrf_constants/geo_em.d01.nc\", geogrid_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7c4d6-1ae3-490d-8332-7eee2252bbdc",
   "metadata": {},
   "source": [
    "### Check progress of copying to scratch\n",
    "\n",
    "Check to see how many of the expected hourly WRF outputs have successfully been copied to scratch space from `$ARCHIVE`. This can take a while.\n",
    "\n",
    "**Note** - only do this if files you are trying to copy have actually been staged. It should theoretically still work regardless, but will take an unknown amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbdae7de-1ef5-40aa-bafb-e43b456cf5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrf_fps, existing_scratch_fps = main.check_raw_scratch(wrf_dir, group, years, raw_scratch_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
