{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091d4969-765f-4d68-9969-28cf0e11859c",
   "metadata": {},
   "source": [
    "# Restack 20km AK WRF data interactively\n",
    "\n",
    "This notebook is for ad-hoc execution of any portion of the pipeline in the [restack_20km](./restack_20km.ipynb) notebook. Use it to restack arbitrary chunks of the WRF data, down to a single variable of a single year for a particular WRF group.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Execute this cell to set up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f93e5ec-dedd-457c-9f6d-a8d9a7a10f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "from tqdm.notebook import tqdm\n",
    "# codebase\n",
    "import luts\n",
    "import restack_20km as main\n",
    "\n",
    "\n",
    "# these paths should be constant for any SNAPer running this pipeline\n",
    "# assumes all folders are created in restack_20km.ipynb\n",
    "base_dir = Path(\"/import/SNAP/wrf_data/project_data/wrf_data\")\n",
    "anc_dir = base_dir.joinpath(\"ancillary\")\n",
    "# monthly WRF file to serve as template\n",
    "template_fp = anc_dir.joinpath(\"monthly_PCPT-gfdlh.nc\")\n",
    "# a script for initializing conda on nodes' shells\n",
    "conda_init_script = anc_dir.joinpath(\"init_conda.sh\")\n",
    "# WRF geogrid file for correctly projecting data and rotating wind data\n",
    "geogrid_fp = anc_dir.joinpath(\"geo_em.d01.nc\")\n",
    "# final output directory for data\n",
    "output_dir = Path(\"/import/SNAP/wrf_data/project_data/wrf_data/restacked\")\n",
    "# slurm directory\n",
    "slurm_dir = base_dir.joinpath(\"slurm\")\n",
    "slurm_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# this env var is always defined if notebook started with anaconda-project run\n",
    "project_dir = Path(os.getenv(\"PROJECT_DIR\"))\n",
    "ap_env = project_dir.joinpath(\"envs/default\")\n",
    "# cp_script = project_dir.joinpath(\"restack_20km/mp_cp.py\") not used on Chinook, $ARCHIVE not accessible from compute nodes\n",
    "restack_script = project_dir.joinpath(\"restack_20km/restack.py\")\n",
    "forecast_times_script = project_dir.joinpath(\"restack_20km/forecast_times.py\")\n",
    "luts_fp = project_dir.joinpath(\"restack_20km/luts.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab527b-66a9-4d79-aea1-1fdf2c78a702",
   "metadata": {},
   "source": [
    "Set user parameters that should not change between various executions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db52a5c-89c4-4b4b-9464-c8d6db124530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Scratch directory path: \n",
      "Email address for slurm: kmredilla@alaska.edu\n"
     ]
    }
   ],
   "source": [
    "# scratch space where data will be copied for performant reading / writing\n",
    "scratch_dir = Path(input(\"Scratch directory path:\") or \"/center1/DYNDOWN/kmredilla/wrf_data\")\n",
    "slurm_email = input(\"Email address for slurm:\")\n",
    "# conda_init_script = \"/home/kmredilla/init_conda.sh\"\n",
    "\n",
    "# where raw wrf outputs will be copied on scratch\n",
    "raw_scratch_dir = scratch_dir.joinpath(\"raw\")\n",
    "\n",
    "# where initially restacked data will be stored on scratch_space\n",
    "restack_scratch_dir = scratch_dir.joinpath(\"restacked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0afe6-7503-455d-a342-b28d8ef3d276",
   "metadata": {},
   "source": [
    "## Restack data\n",
    "\n",
    "\n",
    "### Processing parameters\n",
    "\n",
    "The following arguments are required for a single job of restacking data for a particular variable (or variables), model, scenario, and year (or years):\n",
    "\n",
    "* **WRF Group**: Encoded value specifying the WRF group being worked on, which is just a combination of the model and scenario (or just model, in terms of ERA-Interim).  One of [`era_interim`, `gfdl_hist`, `ccsm_hist`, `gfdl_rcp85`, `ccsm_rcp85`].\n",
    "* **Year(s)**: a list of years to work on specified as integers, such as `[1979, 1980]`, or omit to work on all years available for a given WRF group.\n",
    "* **Variable name(s)**: Name(s) of the variable(s). This is the lower case version of the variable name in the WRF outputs.\n",
    "* **Number of cores**: This is the number of cores to use for parallel tasks.\n",
    "* **Chinook partition**: the desired partition on the Chinook cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad81d3cf-143d-4773-82bb-93155d22507b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "WRF group, one of ['erain_hist', 'gfdl_hist', 'ccsm_hist', 'gfdl_rcp85', 'ccsm_rcp85']: ccsm_hist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRF group selected: ccsm_hist\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Years, a ' '- separated list of years, in 1970-2005. Leave blank for all years: 1971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years selected: ['1971']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter name(s) of WRF variable(s) to re-stack (leave blank for all): ACSNOW\n",
      "Enter number of CPUs to use (valid range: 2-24; leave blank for 24 cores): \n",
      "Enter name of compute partition to use (leave blank for 't1small'): \n"
     ]
    }
   ],
   "source": [
    "group = \"\"\n",
    "while group not in list(luts.groups.keys()):\n",
    "    group = input(f\"WRF group, one of {list(luts.groups.keys())}:\")\n",
    "print(f\"WRF group selected: {group}\")\n",
    "wrf_dir = Path(luts.groups[group][\"directory\"])\n",
    "\n",
    "years = [1738]\n",
    "valid_years = f\"{luts.groups[group]['years'][0]}-{luts.groups[group]['years'][-1]}\"\n",
    "while not all([int(year) in luts.groups[group][\"years\"] for year in years]):\n",
    "    years = input(f\"Years, a ' '- separated list of years, in {valid_years}. Leave blank for all years:\") or luts.groups[group]['years']\n",
    "    if (type(years) == str) and (len(years) > 0):\n",
    "        years = years.split(\" \")\n",
    "print(f\"Years selected: {years}\")\n",
    "\n",
    "varnames = [\"\"]\n",
    "while not all ([varname in luts.varnames for varname in varnames]):\n",
    "    varnames = input(\"Enter name(s) of WRF variable(s) to re-stack (leave blank for all):\") or luts.varnames\n",
    "    if (type(varnames) == str) and (len(varnames) > 0):\n",
    "        varnames = varnames.split(\" \")\n",
    "\n",
    "ncpus = 0\n",
    "while (ncpus < 2) | (ncpus > 24):\n",
    "    ncpus = input(\"Enter number of CPUs to use (valid range: 2-24; leave blank for 24 cores):\") or 24\n",
    "    ncpus = int(ncpus)\n",
    "\n",
    "partition = input(\"Enter name of compute partition to use (leave blank for 't1small'):\") or \"t1small\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ae30e-96b5-43e2-b4a3-1e27308944f1",
   "metadata": {},
   "source": [
    "Create slurm scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208c57ec-7a32-4a5d-8738-9faf6ecb7d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbatch_fps = []\n",
    "year_str = main.get_year_fn_str(years)\n",
    "for varname in varnames:\n",
    "    # write to .slurm script\n",
    "    sbatch_fp = slurm_dir.joinpath(f\"restack_{group}_{year_str}_{varname}.slurm\")\n",
    "    # filepath for slurm stdout\n",
    "    sbatch_out_fp = slurm_dir.joinpath(f\"restack_{group}_{year_str}_{varname}_%j.out\")\n",
    "    sbatch_head = main.make_sbatch_head(\n",
    "        slurm_email, partition, conda_init_script, ap_env\n",
    "    )\n",
    "\n",
    "    args = {\n",
    "        \"sbatch_fp\": sbatch_fp,\n",
    "        \"sbatch_out_fp\": sbatch_out_fp,\n",
    "        \"restack_script\": restack_script,\n",
    "        \"luts_fp\": luts_fp,\n",
    "        \"geogrid_fp\": geogrid_fp,\n",
    "        \"anc_dir\": anc_dir,\n",
    "        \"restacked_dir\": restack_scratch_dir,\n",
    "        \"group\": group,\n",
    "        \"fn_str\": luts.groups[group][\"fn_str\"],\n",
    "        \"years\": years,\n",
    "        \"varname\": varname,\n",
    "        \"ncpus\": ncpus,\n",
    "        \"sbatch_head\": sbatch_head,\n",
    "    }\n",
    "\n",
    "    main.write_sbatch_restack(**args)\n",
    "    sbatch_fps.append(sbatch_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f75b7a5-4bda-4ef1-8137-6ba289560fca",
   "metadata": {},
   "source": [
    "Remove existing slurm output scripts if you fancy it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dadae76f-5592-464e-95b5-d37e285ac1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname in varnames:\n",
    "    _ = [fp.unlink() for fp in list(slurm_dir.glob(f\"*{group}_{year_str}_{varname}_*.out\"))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b573a0-040f-44cd-b8f6-579cc32ee7a0",
   "metadata": {},
   "source": [
    "Submit the `.slurm` scripts with `sbatch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f07b743-d1d9-4a4e-8306-6dc3f7a8aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ids = [main.submit_sbatch(fp) for fp in sbatch_fps]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b826572b-d4b3-4d0a-b470-99d3cb31cc00",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Quality Check\n",
    "\n",
    "### Ensure that all files open and have consistent header info\n",
    "\n",
    "Check this using both `xarray` and GDAL bindings.\n",
    "\n",
    "Dimensions are the sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec0cec-d5a6-49d5-893b-87351654476a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284e312-e67e-4380-9f48-8ab6b5b628b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f3fd2-8af9-4f52-92e5-1040cea3027d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
