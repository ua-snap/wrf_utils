{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96edfbb-e2f0-4e33-a561-dcd21d2a7746",
   "metadata": {},
   "source": [
    "# Production comparison: NCAR CCSM4 RCP85\n",
    "\n",
    "This notebook is for evaluating the results from the comparison of newly restacked files with existing production files.\n",
    "\n",
    "It is meant to serve as a historical record and will not maintain functionality as files are moved.\n",
    "\n",
    "Set up the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5218fdd-8dfa-4f08-bb94-c59515a2a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "# all this code to load the config and luts modules by absolute path\n",
    "project_dir = Path(os.getenv(\"PROJECT_DIR\"))\n",
    "\n",
    "def load_module(path):\n",
    "    \"\"\"https://docs.python.org/3/library/importlib.html#importing-a-source-file-directly\"\"\"\n",
    "    module = path.name.split(\".py\")[0]\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        module, path\n",
    "    )\n",
    "    module_obj = importlib.util.module_from_spec(spec)\n",
    "    sys.modules[module] = module_obj\n",
    "    spec.loader.exec_module(module_obj)\n",
    "    \n",
    "    return module_obj\n",
    "\n",
    "luts = load_module(project_dir.joinpath(\"restack_20km/luts.py\"))\n",
    "config = load_module(project_dir.joinpath(\"restack_20km/config.py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0db28b-fec2-4eb4-8b4e-8112d32b6a72",
   "metadata": {},
   "source": [
    "## Hourly data\n",
    "\n",
    "Load the results from comparing hourly data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e080efc2-6f8e-4856-985e-1d98d7b5e7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_fp = config.anc_dir.joinpath(\n",
    "    \"production_data_comparisons\",\n",
    "    f\"prod_comparison_{luts.groups[config.group]['fn_str']}_hourly.csv\"\n",
    ")\n",
    "hourly_df = pd.read_csv(hourly_fp, parse_dates=[\"timestamp\"])\n",
    "\n",
    "scratch_dir = Path(hourly_df.iloc[0][\"scratch_filename\"]).parent.parent\n",
    "prod_dir = Path(hourly_df.iloc[0][\"prod_filename\"]).parent.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea77a0-ce01-45d1-9f5d-d98b7f52bd17",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Timestamp mismatches\n",
    "\n",
    "Okay looks like we have some missing raw data! Swell...\n",
    "\n",
    "We expect time mismatches with the newly rotated wind data created in 2021. Those wind data time stamps were labeled incorrectly (should not have leap days). \n",
    "However, for all variables (including wind) for the year 2022, the time mismatch is due to some missing WRF files for 2022-10-15, hours 12 and 13:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf331db3-f8ce-4198-b691-548691fd0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[38;5;34m/archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/WRFDS_d01.2022-10-25_10.nc\u001b[0m\u001b[K*\n",
      "\u001b[38;5;34m/archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/WRFDS_d01.2022-10-25_11.nc\u001b[0m\u001b[K*\n",
      "\u001b[38;5;34m/archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/WRFDS_d01.2022-10-25_14.nc\u001b[0m\u001b[K*\n",
      "\u001b[38;5;34m/archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/WRFDS_d01.2022-10-25_15.nc\u001b[0m\u001b[K*\n",
      "\u001b[38;5;34m/archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/WRFDS_d01.2022-10-25_16.nc\u001b[0m\u001b[K*\n",
      "\u001b[38;5;34m/archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/WRFDS_d01.2022-10-25_17.nc\u001b[0m\u001b[K*\n",
      "\u001b[38;5;34m/archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/WRFDS_d01.2022-10-25_18.nc\u001b[0m\u001b[K*\n",
      "\u001b[38;5;34m/archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/WRFDS_d01.2022-10-25_19.nc\u001b[0m\u001b[K*\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "ls /archive/DYNDOWN/DIONE/pbieniek/ccsm/rcp85/hourly/2022/*2022-10-25_1*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a85c94-547e-4432-b901-08d3a71d1f28",
   "metadata": {},
   "source": [
    "So let's make sure that any time mistmatches for variables in non-leap years were all actually in 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa230eea-1ea0-4918-ad9a-aeb25df02aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>scratch_filename</th>\n",
       "      <th>prod_filename</th>\n",
       "      <th>prod_exists</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>arr_result</th>\n",
       "      <th>time_result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>hfx</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/re...</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/ho...</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-12-24 13:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>pcpnc</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/re...</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/ho...</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-11-16 09:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>swupb</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/re...</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/ho...</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-11-26 03:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>cldfra_mid</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/re...</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/ho...</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-12-26 06:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>smois</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/re...</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/ho...</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-12-29 13:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>ubot</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/re...</td>\n",
       "      <td>/import/SNAP/wrf_data/project_data/wrf_data/ho...</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-12-14 17:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         varname                                   scratch_filename  \\\n",
       "397          hfx  /import/SNAP/wrf_data/project_data/wrf_data/re...   \n",
       "882        pcpnc  /import/SNAP/wrf_data/project_data/wrf_data/re...   \n",
       "1738       swupb  /import/SNAP/wrf_data/project_data/wrf_data/re...   \n",
       "2422  cldfra_mid  /import/SNAP/wrf_data/project_data/wrf_data/re...   \n",
       "3363       smois  /import/SNAP/wrf_data/project_data/wrf_data/re...   \n",
       "4241        ubot  /import/SNAP/wrf_data/project_data/wrf_data/re...   \n",
       "\n",
       "                                          prod_filename  prod_exists  \\\n",
       "397   /import/SNAP/wrf_data/project_data/wrf_data/ho...         True   \n",
       "882   /import/SNAP/wrf_data/project_data/wrf_data/ho...         True   \n",
       "1738  /import/SNAP/wrf_data/project_data/wrf_data/ho...         True   \n",
       "2422  /import/SNAP/wrf_data/project_data/wrf_data/ho...         True   \n",
       "3363  /import/SNAP/wrf_data/project_data/wrf_data/ho...         True   \n",
       "4241  /import/SNAP/wrf_data/project_data/wrf_data/ho...         True   \n",
       "\n",
       "               timestamp  arr_result time_result error  \n",
       "397  2022-12-24 13:00:00        True       False   NaN  \n",
       "882  2022-11-16 09:00:00        True       False   NaN  \n",
       "1738 2022-11-26 03:00:00        True       False   NaN  \n",
       "2422 2022-12-26 06:00:00        True       False   NaN  \n",
       "3363 2022-12-29 13:00:00        True       False   NaN  \n",
       "4241 2022-12-14 17:00:00        True       False   NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = hourly_df.query(\"~timestamp.dt.is_leap_year & time_result == False & prod_exists == True\")\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7429389-3d81-461a-8190-57c79ee8a09f",
   "metadata": {},
   "source": [
    "Indeed they are. We are just going to correct this issue here and now. Maybe not the best spot, but at least it will be tracked in this notebook, which should not be updated.\n",
    "\n",
    "Also, since there will be multiple issues to test here, start a running list of which rows have been addressed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea53c4d3-7c08-40a5-80f8-5639a2396f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_addressed = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef8436-c339-4433-938f-73642b648887",
   "metadata": {},
   "source": [
    "### Patching in production data\n",
    "\n",
    "We will want to iterate over all production files for 2022, and just patch the 12 and 13 hour timestamps from the production array into the new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88b6b96-d4e6-4fe1-b600-0dbeb4624420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_scratch(scratch_fp, prod_fp, varname):\n",
    "    # We want to keep everything but the time dimension in the final dataset\n",
    "    scratch_ds = xr.open_dataset(scratch_fp)\n",
    "    try:\n",
    "        _ = scratch_ds.sel(time=\"2022-10-25 12:00:00\")\n",
    "    except KeyError:\n",
    "        prod_ds = xr.open_dataset(prod_fp)\n",
    "        new_scratch_ds = scratch_ds.drop_dims(\"time\")\n",
    "        prod_da_sl = prod_ds[varname].sel(time=slice(\"2022-10-25 12:00:00\", \"2022-10-25 13:00:00\"))\n",
    "        new_scratch_ds[varname] = xr.concat([scratch_ds[varname], prod_da_sl], dim=\"time\").sortby(\"time\")\n",
    "        \n",
    "        # cannot overwrite netcdf file so (permission error with xarray/netcdf4)\n",
    "        #  locking the file or something so we need to save to different file and then rename.\n",
    "        temp_scratch_fp = Path(str(scratch_fp).replace(\".nc\", \"_tmp.nc\"))\n",
    "        new_scratch_ds.to_netcdf(temp_scratch_fp, engine=\"netcdf4\")\n",
    "        _ = temp_scratch_fp.rename(scratch_fp)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03acea6e-ad0a-4ae2-8436-f8ee8e651552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46/46 [6:23:38<00:00, 500.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 36min 3s, sys: 2h 31min 30s, total: 5h 7min 33s\n",
      "Wall time: 6h 23min 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tqdm\n",
    "\n",
    "\n",
    "for varname in tqdm.tqdm(luts.varnames):\n",
    "    varname = varname.lower()\n",
    "    scratch_fp = scratch_dir.joinpath(varname, f\"{varname}_hourly_wrf_NCAR-CCSM4_rcp85_2022.nc\")\n",
    "    prod_fp = prod_dir.joinpath(varname, f\"{varname}_hourly_wrf_NCAR-CCSM4_rcp85_2022.nc\")\n",
    "    patch_scratch(scratch_fp, prod_fp, varname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b381d-c454-404e-a260-ca7927185d86",
   "metadata": {},
   "source": [
    "Check one of the files and make sure the time slice is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d51206fc-865c-4e34-9f29-2c2b5074827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 't2' (yc: 262, xc: 262)>\n",
      "array([[242.11812, 242.25912, 242.41013, ..., 257.6151 , 257.67813, 257.73813],\n",
      "       [241.25212, 241.85812, 242.24713, ..., 259.23914, 259.1111 , 257.37314],\n",
      "       [240.62112, 241.11412, 241.18512, ..., 259.99112, 259.30112, 257.32413],\n",
      "       ...,\n",
      "       [289.78113, 289.68213, 289.62512, ..., 289.06512, 289.05414, 288.93112],\n",
      "       [289.90213, 289.79913, 289.7441 , ..., 289.10312, 289.10812, 288.99213],\n",
      "       [290.02112, 289.95514, 289.91312, ..., 289.00912, 289.03214, 289.05713]],\n",
      "      dtype=float32)\n",
      "Coordinates:\n",
      "  * yc           (yc) float64 -1.824e+05 -2.024e+05 ... -5.382e+06 -5.402e+06\n",
      "  * xc           (xc) float64 -2.61e+06 -2.59e+06 ... 2.59e+06 2.61e+06\n",
      "    lon          (yc, xc) float32 ...\n",
      "    lat          (yc, xc) float32 ...\n",
      "    spatial_ref  int64 ...\n",
      "    time         datetime64[ns] 2022-10-25T12:00:00\n",
      "Attributes:\n",
      "    initial_time:             12/30/2021 (18:00)\n",
      "    forecast_time_units:      hours\n",
      "    forecast_time:            30\n",
      "    level:                    2\n",
      "    parameter_number:         11\n",
      "    parameter_table_version:  2\n",
      "    gds_grid_type:            5\n",
      "    level_indicator:          105\n",
      "    units:                    K\n",
      "    long_name:                Temperature at 2m height\n",
      "    center:                   US National Weather Service - NCEP (WMC)\n",
      "    coordinates:              g5_lat_0 g5_lon_1\n",
      "    grid_mapping:             spatial_ref\n"
     ]
    }
   ],
   "source": [
    "scratch_dir = Path(hourly_df.iloc[0][\"scratch_filename\"]).parent.parent\n",
    "scratch_fp = scratch_dir.joinpath(\"t2\", \"t2_hourly_wrf_NCAR-CCSM4_rcp85_2022.nc\")\n",
    "with xr.open_dataset(scratch_fp) as ds:\n",
    "    print(ds[\"t2\"].sel(time=\"2022-10-25 12:00:00\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef174d-cfff-40bf-bae0-d824f51b3158",
   "metadata": {},
   "source": [
    "Okay so this should have taken care of the issue of mistmatch time stamp test cases for 2022. Consider these issues in the hourly dataframe taken care of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24a495e6-db5e-4190-8c83-f427a7c5fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_addressed.extend(test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e21a7-cfc1-47e9-ba35-92a7a6ec997b",
   "metadata": {},
   "source": [
    "#### Wind leap year mismatches\n",
    "\n",
    "We can now just check that the remaining mismatches are due to incorrectly (time-)indexed wind datasets during leap years. For example, look at dates before and after leap day in 2008:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a911722-2fb8-4e2c-b259-0fb185141468",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_fp = \"/import/SNAP/wrf_data/project_data/wrf_data/hourly_fix/u/u_hourly_wrf_NCAR-CCSM4_rcp85_2008.nc\"\n",
    "scratch_fp = \"/import/SNAP/wrf_data/project_data/wrf_data/restacked/hourly/u/u_hourly_wrf_NCAR-CCSM4_rcp85_2008.nc\"\n",
    "scratch_ds = xr.open_dataset(scratch_fp)\n",
    "prod_ds = xr.open_dataset(prod_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875e14d-010d-4483-bfcf-2a0cea73de06",
   "metadata": {},
   "source": [
    "Before leap day things match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa1d139d-2f53-4771-afee-5e60b365adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = \"2008-01-24 21:00:00\"\n",
    "varname = \"u\"\n",
    "assert np.all(scratch_ds[varname].sel(time=tstamp, plev=50) == prod_ds[varname].sel(time=tstamp, plev=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c2e9d5-3216-4ff8-b33d-bb56d8792253",
   "metadata": {},
   "source": [
    "After leap day, they don't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35566f4f-5ee9-49d1-bea8-03590759435d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m tstamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2008-03-24 21:00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m varname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(scratch_ds[varname]\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39mtstamp, plev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m==\u001b[39m prod_ds[varname]\u001b[38;5;241m.\u001b[39msel(time\u001b[38;5;241m=\u001b[39mtstamp, plev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m))\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tstamp = \"2008-03-24 21:00:00\"\n",
    "varname = \"u\"\n",
    "assert np.all(scratch_ds[varname].sel(time=tstamp, plev=50) == prod_ds[varname].sel(time=tstamp, plev=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83422896-2fb6-46cb-a0fc-e03747bff392",
   "metadata": {},
   "source": [
    "But we know these data should not have leap days. This is probably a bug that was introduced during the repair of the wind data. E.g. see a query for leap day from two production files, wind and non-wind. \n",
    "\n",
    "Wind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4d863cd-0e05-481e-a272-b820f2955188",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_fp = config.base_dir.joinpath(\"hourly_fix/u/u_hourly_wrf_NCAR-CCSM4_rcp85_2008.nc\")\n",
    "prod_ds = xr.open_dataset(prod_fp)\n",
    "_ = prod_ds[\"u\"].sel(time=\"2008-02-29 01:00:00\", plev=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7723f6a9-5ef9-497b-b77a-28cb209e098b",
   "metadata": {},
   "source": [
    "And a non-wind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5d152e9-9be9-4f98-9054-6dfed9343237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No leap day exists\n"
     ]
    }
   ],
   "source": [
    "fp = config.base_dir.joinpath(\"hourly_fix/t2/t2_hourly_wrf_NCAR-CCSM4_rcp85_2008.nc\")\n",
    "with xr.open_dataset(fp) as ds:\n",
    "    try:\n",
    "        _ = ds[\"t2\"].sel(time=\"2008-02-29 01:00:00\")\n",
    "    except KeyError:\n",
    "        _ = ds[\"t2\"].sel(time=\"2008-02-28 01:00:00\")\n",
    "        print(\"No leap day exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14864e62-3b84-4e0a-a9aa-eb2716689ff2",
   "metadata": {},
   "source": [
    "So this issue is only present in the wind data because of us having worked on it more recently, and introducing a bug in the restacking code used then. We will assume that all wind files for leap years that have mismatched arrays are due to this bug (which is now fixed). Verify that all such files were leap years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58e992e6-0507-4598-b123-e96e787e3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = hourly_df.query(\n",
    "    \"time_result == False & arr_result == False & varname in @wind_varnames\"\n",
    ").timestamp.dt.is_leap_year\n",
    "try:\n",
    "    assert np.all(test)\n",
    "    rows_addressed.extend(test.index)\n",
    "except AssertionError:\n",
    "    print(\"Test failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db436f1a-b338-4abc-a50d-29bcc6042446",
   "metadata": {},
   "source": [
    "Now let's look at comparisons that resulted in errors. It looks like these are all files that don't exist because they come from the split year between historical and projected data, 2005. Confirm this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e740a96-d1eb-4602-ae55-697425509e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = hourly_df.query(\n",
    "    \"error == 'FileNotFoundError'\"\n",
    ").timestamp.dt.year == 2005\n",
    "\n",
    "try:\n",
    "    assert np.all(test)\n",
    "    rows_addressed.extend(test.index)\n",
    "except AssertionError:\n",
    "    print(\"Test failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36c157-16b3-4754-9a88-a8ca8f09fede",
   "metadata": {},
   "source": [
    "And it looks like we had one Runtime error. This is probably a corrupt wind file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afeed878-8dd5-48bb-8d15-891ea863bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime errors:  1\n",
      "varname                                                             u\n",
      "scratch_filename    /import/SNAP/wrf_data/project_data/wrf_data/re...\n",
      "prod_filename       /import/SNAP/wrf_data/project_data/wrf_data/ho...\n",
      "prod_exists                                                      True\n",
      "timestamp                                         2057-10-17 02:00:00\n",
      "arr_result                                                      False\n",
      "time_result                                                       NaN\n",
      "error                                                    RuntimeError\n",
      "Name: 3889, dtype: object\n",
      "\n",
      "Still Runtime error\n"
     ]
    }
   ],
   "source": [
    "print(\"Runtime errors: \", len(hourly_df.query(\"error == 'RuntimeError'\")))\n",
    "row = hourly_df.query(\"error == 'RuntimeError'\").iloc[0]\n",
    "print(row)\n",
    "with xr.open_dataset(row[\"prod_filename\"]) as prod_ds:\n",
    "    with xr.open_dataset(row[\"scratch_filename\"]) as scratch_ds:\n",
    "        try:\n",
    "            prod_ds[row[\"varname\"]].sel(\n",
    "                time=row[\"timestamp\"]\n",
    "            ).load()\n",
    "        except RuntimeError:\n",
    "            print(\"\\nStill Runtime error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c64111-0a81-43e5-bdcf-46f92a90f1f7",
   "metadata": {},
   "source": [
    "Track this row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0430683-65dc-4c16-b873-db0b64f4cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_addressed.extend([row.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd3c150-7be6-410c-b5c5-c8a301c1185e",
   "metadata": {},
   "source": [
    "Now tack the rows that were successful comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "59aa0d24-b62a-4f33-88dd-1ef4d1373f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_addressed.extend(hourly_df.query(\"time_result == True & prod_exists == True\").index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f972e8-9ce4-41cc-92fe-4052a872af5a",
   "metadata": {},
   "source": [
    "And verify that we have checked every case in the results dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2fb063a4-bc60-4d06-8355-df4baf4c3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(hourly_df.index) - set(rows_addressed) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0a7cc-88d7-460d-aacd-1715cf034d30",
   "metadata": {},
   "source": [
    "So the hourly data for NCAR CCSM4 RCP 8.5 passes the comparison with production data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f762fa-d4e7-49a3-af2e-fbb32a63db90",
   "metadata": {},
   "source": [
    "## Daily data\n",
    "\n",
    "Load the results from comparing daily data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4af62323-d309-4c25-96cc-0009cd056ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_fp = config.anc_dir.joinpath(\n",
    "    \"production_data_comparisons\",\n",
    "    f\"prod_comparison_{luts.groups[config.group]['fn_str']}_daily.csv\"\n",
    ")\n",
    "daily_df = pd.read_csv(daily_fp, parse_dates=[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8842a115-7066-4fe9-b7b7-62e1ac99bee7",
   "metadata": {},
   "source": [
    "Okay looks like all of the daily files can be accounted for based on the array result comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "225ad143-020a-48b1-a9fc-4ea2caaddd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sorted(list(daily_df.query(\"arr_result == True\").index) + list(daily_df.query(\"arr_result == False\").index))\n",
    "assert np.all(daily_df.index == test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e747cec-3cf3-439d-9885-ba103eb1ae64",
   "metadata": {},
   "source": [
    "And it looks like all of the files that didn't match were due to the missing 2005 files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "164e89ed-9579-48ca-9e26-1c449767ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(daily_df.query(\"arr_result == False\").error == \"FileNotFoundError\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504e99a-30e0-4d4f-8b19-59573b224588",
   "metadata": {},
   "source": [
    "And that covers it for the daily data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
